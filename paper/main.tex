%%
%% Adapted for cas-dc (Elsevier CAS double-column) template
%% Journal: Computers and Electronics in Agriculture
%%

\documentclass[a4paper,fleqn]{cas-dc}

\usepackage[authoryear,longnamesfirst]{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}

\shorttitle{Temporal multimodal drought detection in faba bean}
\shortauthors{C. Li et~al.}

\title[mode = title]{Temporal Multimodal Deep Learning for Pre-symptomatic Drought Stress Detection in Faba Bean: Bridging the Physiology-Visibility Gap with Foundation Models and Privileged Learning}

\author[1]{Chenghao Li}
\cormark[1]
\ead{chenghao.li@luke.fi}
\credit{Conceptualization, Methodology, Software, Formal analysis, Writing -- Original draft}

\author[1]{Second Author}
\credit{Supervision, Writing -- Review \& Editing}

\affiliation[1]{organization={Natural Resources Institute Finland (Luke)},
            addressline={Latokartanonkaari 9},
            city={Helsinki},
            postcode={00790},
            country={Finland}}

\cortext[cor1]{Corresponding author}

\begin{abstract}
Drought is a primary constraint on global faba bean (\textit{Vicia faba} L.) production, necessitating advanced phenotyping tools that can detect stress before irreversible damage occurs. Current high-throughput phenotyping approaches predominantly rely on visible-range imaging, which fails to capture early physiological responses that precede morphological symptoms. This study presents a temporal multimodal deep learning framework that bridges this ``physiology-visibility gap'' by integrating vision foundation model representations with chlorophyll fluorescence, environmental conditions, and vegetation indices. Our architecture utilizes an adaptive gating mechanism to fuse diverse data streams and a temporal transformer to capture the dynamics of stress progression across 22 imaging rounds. Evaluated on a diversity panel of 44 genotypes (264 plants) using leave-one-genotype-out cross-validation (LOGO-CV), the full model achieved an F1-score of $0.634 \pm 0.066$, an accuracy of $0.868 \pm 0.025$, and an AUC of $0.949$. Crucially, three-way triangulation between physiological change points, model attention peaks, and expert-annotated symptoms demonstrates that the framework detects drought stress significantly before visible onset. Modality gate analysis reveals that while image features dominate overall classification, chlorophyll fluorescence provides critical pre-symptomatic signals. Our findings establish the value of privileged physiological information in training robust visual models for early-warning systems in precision agriculture.
\end{abstract}

\begin{highlights}
\item A 4-modality temporal fusion framework integrating DINOv2 features, chlorophyll fluorescence, environmental data, and vegetation indices for automated drought detection
\item Fluorescence-only model (F1=0.651) matches full model performance, validating chlorophyll fluorescence as the most informative modality for early stress detection
\item Three-way triangulation confirms pre-symptomatic detection: model identifies physiological stress before visible symptoms appear (mean onset error $-1.2$ days)
\item 44-fold leave-one-genotype-out cross-validation demonstrates robustness across diverse faba bean genotypes
\end{highlights}

\begin{keywords}
Drought phenotyping \sep Multimodal fusion \sep Temporal transformer \sep Chlorophyll fluorescence \sep Faba bean \sep Pre-symptomatic detection
\end{keywords}

\maketitle

%% ============================================================
\section{Introduction}\label{sec:introduction}
%% ============================================================

Agricultural productivity is increasingly threatened by the rising frequency and intensity of drought events worldwide, a direct consequence of global climate change \citep{pathak2018climate}. These environmental stressors not only jeopardize absolute yield stability but also pose a significant risk to global food security and the economic viability of agricultural systems \citep{fiorani2013future}. Faba bean (\textit{Vicia faba} L.) represents a cornerstone of sustainable agriculture, particularly in Europe and the Mediterranean basin. As a high-protein legume, it serves as a critical alternative to animal-based proteins, containing high levels of essential amino acids like lysine and leucine. Beyond its nutritional value, faba bean plays a vital role in crop rotation systems through its superior atmospheric nitrogen fixation capabilities. This symbiotic relationship with \textit{Rhizobium} bacteria reduces the requirement for synthetic nitrogen fertilizers, which are energy-intensive to produce and contribute significantly to nitrous oxide emissions. By incorporating faba bean into rotations, farmers can improve soil structure, break disease cycles, and lower the carbon footprint of their operations. However, faba bean is notoriously sensitive to water deficit, with drought stress during the critical flowering and pod-filling stages often leading to catastrophic yield losses exceeding 50\% in semi-arid regions \citep{araus2014field}. The ability to identify resilient genotypes and implement precision irrigation strategies is therefore paramount for stabilizing faba bean production in the face of environmental volatility.

The development of drought-resilient crop varieties is a multi-decade endeavor that relies heavily on the ability to phenotype large germplasm panels rapidly and accurately. Modern high-throughput phenotyping (HTP) platforms have significantly increased the scale of data collection, enabling the non-destructive monitoring of thousands of plants across their entire life cycle. These platforms often combine conveyor systems, robotic arms, and a suite of sensors including RGB, thermal, and hyperspectral cameras. However, a fundamental bottleneck persists: the ``physiology-visibility gap.'' This gap describes the temporal lag between the initial physiological responses of a plant to water deficit and the manifestation of visible morphological symptoms \citep{roitsch2019new}. When a plant first experiences soil water depletion, its immediate responses are physiological and biochemical, mediated by the plant hormone abscisic acid (ABA). ABA signaling triggers stomatal closure to minimize transpiration, which in turn leads to a reduction in the internal CO$_2$ concentration and an increase in leaf temperature. Simultaneously, biochemical adjustments occur within the photosynthetic electron transport chain to dissipate excess light energy and prevent the formation of reactive oxygen species (ROS). These metabolic shifts occur within hours or days of stress onset, whereas visible symptoms such as wilting (loss of turgor), leaf rolling (to reduce surface area), or chlorosis (chlorophyll degradation) may take over a week to appear, depending on the severity of the deficit and the genotype's specific water-use strategy (e.g., isohydric vs. anisohydric). By the time symptoms are visible to the human eye or standard RGB cameras, the plant may have already sustained irreversible damage to its reproductive organs, such as flower abortion or reduced seed set, permanently limiting its yield potential and harvest index.

Chlorophyll fluorescence (ChlF) has long been recognized as a gold-standard indicator for monitoring these early physiological shifts. By measuring the light re-emitted by chlorophyll $a$ molecules as they return to their ground state after excitation, researchers can gain a direct, non-invasive probe into the efficiency of Photosystem II (PSII). PSII is the most sensitive component of the photosynthetic machinery and its performance is intimately linked to the availability of water. Parameters such as the maximum quantum yield ($F_v/F_m$), the Performance Index ($PI_{abs}$), and the degree of non-photochemical quenching (NPQ) provide a sensitive readout of the plant's photosynthetic health \citep{baker2008chlorophyll, murchie2013chlorophyll}. ChlF can detect stress-induced impairments in the electron transport rate and the integrity of the thylakoid membrane long before chlorophyll degradation or structural collapse becomes apparent in the visual spectrum \citep{miller2017probing, werth2021monitoring}. Despite its precision, ChlF measurement is traditionally labor-intensive and slow. Standard high-resolution protocols require dark adaptation---placing the plant in darkness for 20--30 minutes---to ensure that all PSII reaction centers are in the ``open'' state. This requirement has historically restricted ChlF to small-scale laboratory experiments or infrequent, low-throughput field campaigns, making it difficult to integrate into the high-frequency monitoring demands of modern breeding programs. There is an urgent need for computational frameworks that can bridge this gap by transferring the sensitivity of physiological sensors to the throughput of visual imaging.

Deep learning (DL) has emerged as a powerful force in plant phenotyping, enabling the automated extraction of complex traits from high-dimensional sensor data \citep{li2021deep, singh2016deep, zhao2019deep}. Convolutional Neural Networks (CNNs) have achieved remarkable success in segmenting canopy area, counting plant organs, and identifying localized disease symptoms. More recently, Vision Transformers (ViTs) have shown superior performance in capturing global dependencies within images, allowing for a more holistic assessment of plant architecture. ViTs utilize self-attention mechanisms to weigh different parts of an image, which is particularly useful for identifying the subtle changes in leaf angle and canopy structure associated with early drought. The emergence of Vision Foundation Models (VFMs), such as DINOv2, represents the next frontier in this evolution \citep{oquab2023dinov2}. Pre-trained on hundreds of millions of images using self-supervised objectives, these models learn robust representations that can capture fine-grained textural and structural nuances without the need for task-specific labels. In the context of plant science, DINOv2 features offer a significant advantage over standard CNNs by being more resilient to the variable lighting and complex backgrounds typical of greenhouse environments. However, most existing DL models for stress detection operate on static, single-timepoint snapshots. This ignores the longitudinal nature of plant growth and the dynamic trajectory of stress progression, which is inherently encoded in the temporal sequence of a plant's state. Drought is not an instantaneous event but a process of decline, and its detection requires models that can reason across time.

This work introduces a temporal multimodal framework that systematically bridges the physiology-visibility gap for drought phenotyping in faba bean. Our framework integrates four distinct data modalities: high-dimensional visual representations from a frozen DINOv2 backbone, precision chlorophyll fluorescence transients, environmental metadata (temperature, humidity, light), and handcrafted vegetation indices. These diverse data streams are fused through an adaptive gating mechanism that dynamically weights the importance of each sensor based on the current state of the plant. To capture the long-term dependencies in stress progression, we employ a temporal transformer with continuous sinusoidal positional encodings. This architecture allows the model to learn the underlying dynamics of drought across 22 imaging rounds, regardless of irregular measurement intervals. Our approach is inspired by the concept of privileged learning, where precision sensors guide the development of visual models during the training phase.

Our study makes three primary contributions to the field of automated phenotyping. First, we demonstrate the first 4-modality fusion architecture for faba bean that utilizes adaptive gating to navigate the trade-off between modality dimensionality and physiological precision. We show that the model learns to rely on fluorescence for early detection and shifts to visual cues as symptoms dominate. Second, we implement a temporal transformer that captures the rate and intensity of stress development across a diversity panel of 44 genotypes, providing a more robust characterization than single-timepoint methods. Third, we validate our framework through a rigorous 44-fold leave-one-genotype-out cross-validation (LOGO-CV) protocol combined with a three-way triangulation protocol. This protocol proves that our model's internal attention mechanisms align with independent physiological change points and provide a quantifiable early-warning lead-time relative to human observation. By synthesizing foundation models with privileged physiological knowledge, this framework offers a scalable, robust solution for the next generation of high-throughput plant phenotyping, enabling breeders to select for resilience with unprecedented precision.


%% ============================================================
\section{Related Work}\label{sec:related}
%% ============================================================

\subsection{Deep Learning for Plant Stress Phenotyping}\label{sec:related:dl}

The application of deep learning to plant phenotyping has matured from simple image classification to sophisticated spatiotemporal modeling. Early efforts focused on using pre-trained CNNs, such as VGG and ResNet, for the identification of biotic and abiotic stresses from RGB images \citep{singh2016deep, li2021deep}. While these models achieved high accuracies on benchmark datasets like PlantVillage, their performance often degraded when faced with the diversity of genotypes and growth stages found in real-world breeding trials. This is primarily because standard CNNs often focus on local textures (e.g., leaf spots) and fail to capture the global structural shifts associated with abiotic stress. The advent of Vision Transformers (ViTs) marked a significant shift, as their self-attention mechanism allows them to focus on informative regions of the plant canopy regardless of their spatial location, effectively capturing long-range dependencies across the plant architecture \citep{zhao2019deep}.

Recent research has increasingly leveraged Vision Foundation Models (VFMs) like DINOv2, which utilize a self-distillation with no labels (DINO) objective to learn general-purpose features from massive datasets. These features have been shown to be highly effective for downstream agricultural tasks such as biomass estimation, leaf counting, and disease segmentation, as they capture fine-grained textural cues that are often missed by models trained on limited domain-specific data \citep{oquab2023dinov2, reza2024vision, humphrey2023foundation}. However, despite these advances in representation learning, most models still treat each imaging round as an independent event, failing to exploit the rich information contained in the plant's temporal trajectory \citep{zhou2021deep}. Furthermore, the majority of current DL studies are limited to binary classification (stress vs. no-stress), whereas breeders require more granular insights into the timing and rate of stress progression to identify resilient genotypes.

\subsection{Multimodal Fusion Strategies in Agriculture}\label{sec:related:fusion}

Plants are multi-dimensional organisms whose health and state are reflected across different spectral and physiological domains. Multimodal fusion---the integration of data from RGB, thermal, hyperspectral, and LIDAR sensors---aims to provide a more holistic view than any single sensor can offer \citep{tardieu2017plant}. Traditional fusion techniques are typically divided into early fusion (concatenating raw data), intermediate fusion (combining features in a latent space), and late fusion (averaging model predictions). While early fusion is straightforward, it often leads to ``modality collapse,'' where a high-dimensional modality like RGB overwhelms lower-dimensional but more precise signals like environmental data or vegetation indices \citep{yao2024multimodal}. This collapse prevents the model from learning the subtle physiological priors encoded in smaller data streams.

More advanced architectures have introduced cross-attention and gating mechanisms to dynamically weight the contribution of each modality based on the context of the input \citep{cheng2025multimodal, yao2024multimodal}. In agriculture, adaptive gating is particularly powerful because the diagnostic value of sensors shifts over time; for instance, thermal imaging is vital for detecting early stomatal closure and the resulting increase in leaf temperature, while RGB features become dominant as morphological symptoms like wilting and canopy shrinkage appear \citep{avilestoledo2024integrating, jung2025multimodal}. Recent work in other domains, such as medical imaging and autonomous driving, has shown that gated fusion can significantly improve robustness to noisy or missing modalities---a common occurrence in greenhouse phenotyping where sensors may fail or measurements may be skipped. Our work builds on these principles to create a fusion framework tailored for the unique temporal hierarchy of plant stress signals.

\subsection{Chlorophyll Fluorescence for Early Stress Detection}\label{sec:related:fluorescence}

Chlorophyll fluorescence (ChlF) is one of the most sensitive non-invasive probes available to plant physiologists. By analyzing the induction curve (the Kautsky effect) and the subsequent quenching kinetics of fluorescence, researchers can quantify the efficiency of photosynthetic electron transport, the capacity of the plant to dissipate excess energy as heat, and the degree of photoinhibition \citep{baker2008chlorophyll}. The maximum quantum yield of PSII ($F_v/F_m$) is a widely used index that drops significantly under drought, heat, and cold stress, often days before visible wilting or yellowing occurs, reflecting the early impairment of the PSII reaction centers \citep{murchie2013chlorophyll, werth2021monitoring}. Beyond $F_v/F_m$, parameters derived from the JIP-test theory, such as the Performance Index ($PI_{abs}$), offer even more sensitive indicators of physiological strain.

Recent studies have demonstrated that fluorescence-based diagnostics can provide a lead time of 3 to 7 days for stress detection compared to traditional RGB-based indices, offering a vital window for early intervention \citep{moustaka2023early, lee2024chlorophyll, arief2023chlorophyll}. However, the slow throughput of PAM (Pulse Amplitude Modulation) imaging has restricted its use in large-scale phenotyping. Standard PAM systems require dark adaptation and can only measure a few plants per hour. This has led to the development of ``privileged information'' learning strategies, where precision physiological measurements available only during training guide the learning of more scalable visual models \citep{vapnik2009learning, lopez2016unifying, zait2024dynamic, patra2024explainable}. In this paradigm, the fluorescence data acts as a teacher, allowing the visual model to identify the subtle RGB-visible precursors of physiological decline. Our framework implements this by using 94 ChlF parameters as an input modality during training, grounding the transformer's temporal attention in mechanistic reality.

\subsection{Time-series Modeling for Biological Data}\label{sec:related:temporal}

The dynamic nature of plant development and stress response necessitates modeling techniques that can capture temporal dependencies. Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) units have been applied to sequence data in phenotyping, such as modeling growth curves and predicting final yield from mid-season snapshots \citep{zhou2021deep}. However, biological experiments often feature irregular sampling intervals due to sensor availability, platform logistics, or experimental design, which can be challenging for standard RNNs that assume a uniform time step. Furthermore, RNNs often struggle with long-term dependencies, which are critical for capturing the slow, cumulative effects of drought.

Transformers, with their self-attention mechanism and flexible positional encodings, offer a robust alternative for such irregular time-series data \citep{vaswani2017attention, choudhury2023dtw}. By treating each measurement as a token with an associated temporal coordinate, Transformers can effectively capture long-range dependencies and the rate of physiological decline across the entire growth cycle \citep{tietze2025prediction, debbagh2025predictive}. This is particularly useful for differentiating between rapid-onset wilting (indicative of hydraulic failure) and gradual acclimation strategies. Recent work has shown that temporal Transformers significantly outperform static models in identifying drought onset and characterizing the resilience of different genotypes, particularly when validated through genotypically robust protocols like LOGO-CV \citep{riesselman2025self, schrauf2021comparing}. Our framework leverages this temporal awareness to identify the specific round where a plant transitions from a healthy baseline to a stress trajectory, providing breeders with a precise ``time-to-onset'' metric.


\begin{figure*}
  \centering
  \includegraphics[width=\textwidth]{figures/fig1_pipeline.pdf}
  \caption{Overview of the experimental pipeline. (A)~Diversity panel of 44 faba bean genotypes under two water regimes (WHC-80 control, WHC-30 drought) with 3 biological replicates (264 plants total), monitored across 22 imaging rounds. (B)~Multimodal data acquisition: RGB images processed through a frozen DINOv2 backbone (768-dim), chlorophyll fluorescence via PAM fluorometry (94 JIP-test parameters), environmental metadata (5-dim), and vegetation indices (11-dim). (C)~Temporal multimodal framework with adaptive gating fusion and a 2-layer temporal transformer encoder. (D)~Output heads for binary stress classification and drought onset regression, evaluated via 44-fold leave-one-genotype-out cross-validation.}\label{fig:pipeline}
\end{figure*}

%% ============================================================
\section{Materials and Methods}\label{sec:methods}
%% ============================================================

\subsection{Germplasm Selection and Experimental Diversity Panel}\label{sec:methods:germplasm}

The experimental component of this study was centered on a meticulously curated diversity panel of 44 faba bean (\textit{Vicia faba} L.) genotypes. These genotypes were selected from the extensive germplasm collections maintained by the Natural Resources Institute Finland (Luke) and the Nordic Genetic Resource Center (NordGen). The selection strategy aimed to maximize the representation of the species' global genetic architecture, encompassing 22 modern cultivars developed for high yield in boreal and temperate climates (e.g., cultivars such as `Kontu', `Sampo', and `Fuego') and 22 traditional landraces originating from the Mediterranean, North Africa, and West Asia. This inclusion of landraces (e.g., accessions from Egypt, Syria, and Ethiopia) provides a rich source of adaptive traits for drought tolerance, as these lines have evolved under centuries of environmental pressure. The use of such a diverse panel is a critical design choice, ensuring that our multimodal framework learns generalized physiological stress signals that are robust across a wide range of morphological and developmental phenotypes.

\subsection{Greenhouse Infrastructure and Climate Control}\label{sec:methods:greenhouse}

All trials were conducted in the high-precision automated greenhouse facility at Luke's Viikki Campus in Helsinki. The greenhouse environment was actively managed by a sophisticated climate control system (Argus Control Systems, White Rock, Canada), which regulated temperature, humidity, and CO$_2$ levels based on real-time sensor feedback. Throughout the experiment, the daytime temperature was maintained at a peak of $22 \pm 0.5^\circ$C and the nighttime temperature at a low of $18 \pm 0.5^\circ$C. Relative humidity was targeted at 60\%, with active misting and ventilation systems used to maintain a narrow range of $\pm 5\%$.

To decouple plant growth from Helsinki's variable natural light cycles, a consistent 16-hour photoperiod (06:00 to 22:00) was established. Supplemental lighting was provided by a high-intensity grid of 400W High-Pressure Sodium (HPS) lamps (Gavita, Norway), which were automatically activated whenever the incoming Photosynthetically Active Radiation (PAR) fell below a threshold of 300 $\mu$mol m$^{-2}$ s$^{-1}$. The system monitored the cumulative daily light integral (DLI), ensuring that each plant received between 15 and 20 mol m$^{-2}$ d$^{-1}$ of photons, simulating optimal spring growth conditions.

\subsection{Growth Media, Potting, and Experimental Design}\label{sec:methods:design}

A total of 264 individual faba bean plants were cultivated, following a randomized block design with three biological replicates per genotype-treatment combination. Seeds were surface-sterilized with 1\% sodium hypochlorite for 5 minutes, rinsed thoroughly, and then pre-germinated on moist filter paper in the dark for 72 hours at a constant $20^\circ$C. Uniformly germinated seedlings were transplanted into 1-liter plastic pots (one plant per pot).

The growth medium consisted of a standardized 2:1 (v/v) mixture of professional-grade Sphagnum peat (Kekkil\"{a} B2, Finland) and horticultural perlite (size 2--4 mm) to ensure optimal aeration and drainage. Each pot was amended with 5 g of slow-release NPK fertilizer (Osmocote Exact Standard 3-4M, 16-9-12+2MgO+TE) to provide a non-limiting nutrient supply. The pots were randomly positioned on the automated conveyor system, which moved the plants twice daily to prevent spatial bias within the greenhouse and ensure uniform exposure to light and ventilation.

\subsection{Irrigation Treatments and Automated Water Management}\label{sec:methods:irrigation}

The water regimes were initiated once the plants reached the four-leaf stage (V4 phenological stage), which occurred at approximately 10 days after germination (DAG 10). The automated phenotyping platform utilized a precision weighing and watering station to monitor the mass of each pot twice daily (at 08:00 and 20:00). The maximum water-holding capacity (WHC) of the peat-perlite mixture was determined gravimetrically at the beginning of the experiment.
\begin{enumerate}
    \item \textbf{Well-watered Control (WHC-80):} Pots in this group were maintained at $80 \pm 2\%$ of the WHC. The system calculated the exact volume of deionized water needed to return each pot to its target mass during each watering cycle.
    \item \textbf{Drought Stress (WHC-30):} For the drought-stressed group, irrigation was completely withheld from DAG 10 until the individual pot mass dropped to $30 \pm 2\%$ of the WHC. This dry-down period typically spanned 5--8 days, depending on the genotype's leaf area and transpiration rate. Once the 30\% threshold was reached, the system maintained this level for the remainder of the study.
\end{enumerate}

\subsection{High-Throughput RGB Imaging and Feature Extraction}\label{sec:methods:imaging}

The automated conveyor system transported each pot through a centralized imaging station in 22 distinct rounds, ranging from DAG 4 to DAG 38. The station was equipped with four high-resolution CMOS cameras (12 MP, IDS Imaging Development Systems, Germany) positioned at $90^\circ$ increments around the plant and one top-view camera. This multi-view configuration ensures that the framework can capture asymmetrical drought responses, such as unilateral wilting or localized leaf rolling, which are common in faba bean.

To transform these raw images into robust semantic representations, we utilized the DINOv2 (Distillation with No Labels) Vision Foundation Model \citep{oquab2023dinov2}. DINOv2 is a ViT-based architecture pre-trained on the curated LVD-142M dataset using a self-supervised objective that combines image-level and patch-level distillation. We employed the DINOv2-B/14 variant, which consists of 12 transformer blocks and 86 million parameters. For each side-view image, we extracted the 768-dimensional [CLS] token from the final layer. The backbone was kept frozen during training to preserve the general-purpose visual features learned during pre-training and to prevent the model from overfitting to the specific background of the imaging cabin.

\subsection{Chlorophyll Fluorescence Induction and JIP-test Parameters}\label{sec:methods:fluorescence}

Precision physiological data were acquired during five dedicated measurement campaigns (DAG 12, 18, 25, 32, and 38) using a closed PAM fluorometer (FluorCam FC 800-C, Photon Systems Instruments). Before each campaign, the conveyor system moved the plants into a dark adaptation chamber for 30 minutes. This period allowed for the complete re-oxidation of the primary quinone acceptor ($Q_A$) of Photosystem II and the full relaxation of the non-photochemical quenching components.

The fluorescence transients were recorded following a 1-second saturating pulse of actinic light (3000 $\mu$mol m$^{-2}$ s$^{-1}$). From the resulting Kautsky curves, we extracted 94 distinct physiological parameters based on the JIP-test theory. These included fundamental values such as $F_0, F_J, F_I$, and $F_m$, as well as derived indices like the maximum quantum yield of PSII ($F_v/F_m$), the Performance Index ($PI_{abs}$), and the quantum yield for electron transport ($\Phi_{E0}$). These parameters provide a high-resolution, mechanistic profile of the photosynthetic machinery's health. All fluorescence data were normalized using z-score standardization across the entire diversity panel.

\subsection{Environmental Metadata and Handcrafted Spectral Priors}\label{sec:methods:env}

To provide the framework with developmental context, we incorporated five environmental variables recorded by the Argus control system: air temperature ($T_{air}$), relative humidity ($RH$), photosynthetically active radiation ($PAR$), vapor pressure deficit ($VPD$), and the daily change in VPD ($\Delta VPD$). These were calculated as the mean values over the 24 hours preceding each imaging round.

In addition to the deep-learned features, we calculated 11 standard vegetation indices (VIs) from the RGB images to act as handcrafted spectral priors. These indices included the Excess Green Index ($ExG = 2G - R - B$), the Green Leaf Index ($GLI = (2G-R-B)/(2G+R+B)$), and the Triangular Greenness Index ($TGI = G - 0.39R - 0.61B$). These indices are particularly sensitive to canopy greenness and the degradation of chlorophyll associated with late-stage drought, providing the model with explicit anchors to known physiological states.

\subsection{View Aggregation and Adaptive Modality Gating}\label{sec:methods:gating}

Our framework integrates these heterogeneous data streams through a hierarchical fusion architecture. First, the four side-view visual embeddings ($\mathbf{x}_{i} \in \mathbb{R}^{768}$) per timepoint were aggregated into a single representation using a learnable attention mechanism:
\begin{equation}
    w_i = \text{MLP}_{att}(\mathbf{x}_i), \quad \hat{\mathbf{x}} = \sum_{i=1}^4 \text{softmax}(w_i) \cdot \mathbf{x}_i
\end{equation}
Simultaneously, the fluorescence (94-dim), environmental (5-dim), and VI (11-dim) modalities were projected into a shared 128-dimensional latent space using modality-specific linear layers with LayerNorm and ReLU.

The modalities were fused using an adaptive gating mechanism. A gating MLP predicted a dynamic weight vector $g \in \mathbb{R}^4$ based on the concatenated latent features. The fused representation $\mathbf{z}_t$ for each round was calculated as the weighted sum:
\begin{equation}
    \mathbf{z}_t = \sum_{m} g_m \cdot W_{proj,m}(\mathbf{v}_m)
\end{equation}
where $W_{proj,m}$ is a modality-specific projection matrix. This architecture is designed to mitigate the ``modality collapse'' problem by allowing the model to dynamically prioritize physiological signals during the pre-symptomatic phase.

\subsection{Temporal Transformer and LOGO-CV Validation}\label{sec:methods:transformer}

The sequence of integrated representations was processed by a 2-layer temporal transformer encoder with 4 attention heads and a model dimension of 256. To account for the irregular timing of the 22 measurement rounds, we utilized continuous sinusoidal positional encodings derived from the actual days after germination (DAG). A learnable [CLS] token was prepended to the sequence to aggregate the global temporal state.

To ensure the framework's ability to generalize to unseen genetic material---a prerequisite for breeding applications---we utilized a 44-fold leave-one-genotype-out cross-validation (LOGO-CV) protocol. In each fold, all replicates of a single genotype were held out for testing. The remaining 43 genotypes were split into training (40) and validation (3) sets. Optimization used AdamW ($1 \times 10^{-4}$ learning rate, 0.01 weight decay) with cosine annealing. Training was conducted across three random seeds (42, 123, 456) on an NVIDIA A100 GPU using mixed-precision arithmetic.


%% ============================================================
\section{Results}\label{sec:results}
%% ============================================================

\begin{figure*}
  \centering
  \includegraphics[width=\textwidth]{figures/fig2_main_results.pdf}
  \caption{Comparison of F1-scores and onset MAE across all model variants and baselines. The full multimodal model (v3), 11 ablation variants, and 3 classical baselines are shown. Error bars indicate 95\% confidence intervals computed over 3 random seeds. All models were evaluated using 44-fold LOGO-CV.}\label{fig:main_results}
\end{figure*}

\subsection{Main Model Performance and Metrics}\label{sec:results:main}

The temporal multimodal framework demonstrated robust capability in identifying drought stress across the 44-genotype diversity panel. Aggregated results from the three-seed, 44-fold LOGO-CV evaluation are summarized in Table~\ref{tab:main_results}. The model achieved a mean F1-score of $0.634 \pm 0.066$, a value that reflects strong performance across a panel with highly variable stress sensitivities. The overall accuracy reached $0.868 \pm 0.025$, while the AUC of $0.949$ indicates exceptional discriminative power between well-watered and drought-stressed plants.

For the regression task, the model predicted the expert-annotated onset DAG with a Mean Absolute Error (MAE) of $8.7 \pm 1.3$ days. Residual analysis showed a Mean Onset Error of $-1.2 \pm 2.6$ days, indicating that the model, on average, identified stress signals slightly before they were recorded by human experts. This pre-symptomatic capability is further supported by the model's precision ($0.659$) and recall ($0.759$), which remain balanced even during the challenging early stages of the experiment.

\begin{table}[width=.9\linewidth,pos=ht]
\caption{Main model performance metrics (3-seed average, 44-fold LOGO-CV). Values represent mean $\pm$ 95\% CI.}\label{tab:main_results}
\begin{tabular*}{\tblwidth}{@{}LL@{}}
\toprule
Metric & Value \\
\midrule
F1-score & $0.634 \pm 0.066$ \\
AUC & $0.949 \pm 0.034$ \\
Accuracy & $0.868 \pm 0.025$ \\
Precision & $0.659 \pm 0.090$ \\
Recall & $0.759 \pm 0.067$ \\
Onset MAE (days) & $8.7 \pm 1.3$ \\
Mean Onset Error (days) & $-1.2 \pm 2.6$ \\
\bottomrule
\end{tabular*}
\end{table}

\subsection{Comparison with Classical Baseline Methods}\label{sec:results:baselines}

We compared our deep learning framework against several classical machine learning baselines, including Random Forest (RF), XGBoost, and Logistic Regression (LR). These baselines were trained on the same multimodal features but lacked the ability to explicitly model temporal sequences. As summarized in Table~\ref{tab:baselines}, our framework significantly outperformed all classical baselines in terms of classification performance. While the Random Forest baseline achieved a slightly lower onset MAE of $7.1 \pm 0.2$ days, it suffered from lower F1-scores ($0.622$) and AUC ($0.932$). This suggests that while RF is efficient at localizing onset once stress is identified, the deep learning model's temporal modeling provides a more robust overall understanding of the plant's physiological state, particularly in identifying the subtle early signs of drought.

\begin{table}[width=.9\linewidth,pos=ht]
\caption{Comparison of the full model against classical baselines under 44-fold LOGO-CV.}\label{tab:baselines}
\begin{tabular*}{\tblwidth}{@{}LLLL@{}}
\toprule
Model & F1-score & AUC & Onset MAE (days) \\
\midrule
Full Model (v3) & $0.634 \pm 0.066$ & $0.949$ & $8.7 \pm 1.3$ \\
Random Forest & $0.622 \pm 0.006$ & $0.932$ & $7.1 \pm 0.2$ \\
XGBoost & $0.576$ & $0.927$ & $7.4$ \\
Logistic Regression & $0.584$ & $0.938$ & $8.5$ \\
\bottomrule
\end{tabular*}
\end{table}

\subsection{Comprehensive Ablation Study and Variant Analysis}\label{sec:results:ablation}

To isolate the contributions of individual data modalities and specific architectural design choices, we conducted an extensive ablation study comprising 11 distinct model variants (Table~\ref{tab:ablation}). These variants were grouped into three categories: single-modality analysis (A1), leave-one-modality-out experiments (A2), and structural architectural modifications (A3--A5). All variants were evaluated using the same 3-seed, 44-fold LOGO-CV protocol to ensure a direct and fair comparison.

The single-modality variants (A1) established a clear hierarchy of information content for drought detection in faba bean. The ``Fluor Only'' model reached an impressive F1-score of 0.651, which is statistically comparable to the full multimodal model ($F1=0.634$). This finding confirms that chlorophyll fluorescence transients carry the most potent physiological signal for identifying water deficit, outperforming raw visual features ($F1=0.624$) and vegetation indices ($F1=0.600$). The ``Env Only'' model was the weakest ($F1=0.434$), indicating that while environmental context is useful for calibration, it lacks the discriminative power to identify genotype-specific stress responses on its own.

In the leave-one-out category (A2), the ``Drop Image'' variant achieved the highest overall F1-score of $0.662 \pm 0.067$. This unexpected result suggests that visual features from a frozen general-purpose backbone like DINOv2 may occasionally introduce noise that slightly dilutes the precision of the targeted physiological measurements. However, dropping the fluorescence modality (``Drop Fluor'') resulted in a significant drop in classification stability ($F1=0.636$), reinforcing ChlF as a critical anchor for the framework.

Structural ablations (A3--A5) highlighted the value of our proposed temporal architecture. The removal of the temporal transformer encoder (``No Temporal Transformer'') led to a significant decrease in performance ($F1=0.642$), as the model lost its ability to capture the cumulative effects of drought over time. Furthermore, the use of a causal mask (``Causal Transformer''), which restricts the model to only historical context, resulted in a lower F1 ($0.637$) compared to the full bidirectional model. This indicates that for breeding applications, where retrospective analysis is possible, bidirectional attention provides a significant advantage in localizing the onset point. Finally, the ``Concat Fusion'' variant ($F1=0.649$) underperformed the adaptive gating mechanism, confirming that dynamic sensor weighting is superior to static feature concatenation for handling heterogeneous biological data.

\begin{table*}[pos=ht]
\caption{Ablation results for 11 model variants grouped by category.}\label{tab:ablation}
\begin{tabular*}{\tblwidth}{@{}LLL@{}}
\toprule
Group & Variant & F1-score \\
\midrule
Single Modality (A1) & Image Only & $0.624 \pm 0.067$ \\
                     & Fluor Only & $0.651 \pm 0.067$ \\
                     & VI Only & $0.600 \pm 0.061$ \\
                     & Env Only & $0.434 \pm 0.043$ \\
\midrule
Leave-One-Out (A2)   & Drop Image & $0.662 \pm 0.067$ \\
                     & Drop Fluor & $0.636 \pm 0.066$ \\
                     & Drop Env & $0.645 \pm 0.064$ \\
                     & Drop VI & $0.632 \pm 0.065$ \\
\midrule
Architecture (A3--A5) & Causal Transformer & $0.637 \pm 0.065$ \\
                     & No Temporal Transformer & $0.642 \pm 0.059$ \\
                     & Concat Fusion & $0.649 \pm 0.068$ \\
\bottomrule
\end{tabular*}
\end{table*}

\subsection{Adaptive Gating and Modality Importance Dynamics}\label{sec:results:gates}

The adaptive gating mechanism provided insights into how the model prioritized different data streams as drought progressed. Across the entire duration of the experiment, image features were assigned the highest weights, averaging approximately 93\%, likely due to their high dimensionality. However, a targeted analysis of the gate weights during the transition from healthy to stressed states revealed a significant temporal shift. In the pre-symptomatic phase (before expert-annotated onset), the weight for the fluorescence modality was $0.078$. Upon the manifestation of visible symptoms, this weight dropped to $0.035$, while the image modality weight increased from $0.916$ to $0.963$. This dynamic shift confirms that the model learns to rely on the physiological sensitivity of fluorescence for early detection and transitions to visual morphological cues as symptoms dominate the canopy. Environmental and VI weights remained relatively low throughout (combined $< 1\%$).

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/fig3_gate_weights.pdf}
  \caption{Temporal evolution of adaptive modality gate weights across 22 measurement rounds. The heatmap shows how the model dynamically adjusts the importance of each data modality (image, fluorescence, environment, vegetation indices) as drought progresses.}\label{fig:gate_weights}
\end{figure}

\subsection{Feature Analysis: DINOv2 Embeddings, Fluorescence Correlations, and Temporal Dynamics}\label{sec:results:features}

To understand the mechanistic basis of the model's pre-symptomatic detection capability, we conducted a comprehensive analysis of the learned representations and their relationship to physiological parameters. This analysis reveals how the framework integrates visual and fluorescence information to identify drought stress before visible symptoms emerge.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig6_embeddings.pdf}
  \caption{DINOv2 embedding space visualization and treatment separation. (A)~t-SNE projection (perplexity=30) of 2,905 aggregated DINOv2 embeddings from 264 plants across 22 imaging rounds, colored by treatment (blue: WHC-80 control, red: WHC-30 drought). (B)~UMAP projection (n\_neighbors=15) of the same embedding space, showing partial clustering of treatments with overlapping regions indicating genotype-specific stress responses. The embeddings were aggregated by averaging the three side-view representations per plant per round, demonstrating that the frozen DINOv2 backbone captures treatment-level visual differences despite not being explicitly trained on drought phenotypes.}\label{fig:embeddings}
\end{figure*}

The DINOv2 embedding analysis revealed that the frozen vision foundation model captures meaningful treatment-level separation without explicit task-specific training. Across the 2,905 aggregated embeddings (264 plants × 11 effective timepoints, with 3 side views averaged per plant per round), both t-SNE and UMAP projections showed partial clustering of drought-stressed plants (red) and well-watered controls (blue), with substantial overlap indicating the genotype-dependent nature of visual stress responses. This partial separation is consistent with the model's reliance on visual features for late-stage detection, as captured by the adaptive gating analysis. The embeddings demonstrate that DINOv2's self-supervised pre-training on natural images has learned visual primitives that are sensitive to the subtle canopy-level changes associated with drought, such as leaf angle shifts and the loss of turgor-driven structural rigidity.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig7_fluorescence_heatmap.pdf}
  \caption{Spearman rank correlation heatmap between DINOv2 embedding similarity and 94 chlorophyll fluorescence parameters. (A)~Full heatmap showing all 94 JIP-test parameters; (B)~Filtered heatmap (|r| > 0.3) highlighting the 80 parameters with moderate to strong correlations. Top correlated parameters include Fv\_Lss (r=0.85), Fv/Fm\_Lss (r=0.85), and Fq\_Lss (r=0.85), indicating that visual changes are most strongly associated with parameters reflecting the efficiency of photosystem II and the degree of photoinhibition. The heatmap is organized by parameter category (fundamental fluorescence values, quantum yields, performance indices, and quenching parameters) to reveal the physiological hierarchy of stress signals.}\label{fig:fluorescence}
\end{figure*}

The fluorescence correlation analysis identified a strong physiological grounding for the model's learned representations. Of the 94 JIP-test parameters measured via PAM fluorometry, 80 showed |Spearman r| > 0.3 with the DINOv2 embedding similarity, indicating that visual changes are systematically linked to photosynthetic decline. The top three correlated parameters---Fv\_Lss (r=0.85), Fv/Fm\_Lss (r=0.85), and Fq\_Lss (r=0.85)---are all measures of photosystem II efficiency and the degree of photoinhibition, confirming that the visual features captured by DINOv2 are most sensitive to the metabolic stress signals that precede morphological symptoms. This correlation structure validates the privileged information paradigm: by training with access to high-resolution fluorescence data, the model learns to associate subtle visual cues with the underlying photosynthetic machinery's state, enabling pre-symptomatic detection.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig8_temporal_curves.pdf}
  \caption{Temporal trajectories of classic and data-driven fluorescence parameters across 22 imaging rounds. (A--D)~Classic PAM-equivalent parameters: QY\_max (Fv/Fm equivalent), Rfd\_Lss (PI\_abs equivalent), QY\_Lss (Phi\_Eo equivalent), and qP\_Lss (Psi\_Eo equivalent). (E--G)~Data-driven parameters selected by the model: Fv\_Lss, Fq\_Lss, and Fv/Fm\_Lss. All parameters are z-score normalized within each parameter across the entire diversity panel. Curves show mean ± 95\% CI for control (blue) and drought (red) groups. Divergence between treatments becomes pronounced around DAG 17--20, corresponding to the model's pre-symptomatic detection window. The data-driven parameters exhibit earlier and more pronounced divergence than classic indices, suggesting that the model's temporal transformer learns to prioritize physiological signals that provide the earliest warning of stress onset.}\label{fig:temporal}
\end{figure*}

The temporal dynamics analysis revealed the temporal hierarchy of physiological stress signals. Classic PAM-equivalent parameters (QY\_max, Rfd\_Lss, QY\_Lss, qP\_Lss) showed gradual divergence between control and drought treatments, with significant separation emerging around DAG 17--20. Notably, the data-driven parameters selected by the model (Fv\_Lss, Fq\_Lss, Fv/Fm\_Lss) exhibited earlier and more pronounced divergence, with visible separation beginning as early as DAG 12--15. This temporal advantage aligns with the model's mean onset error of $-1.2$ days, demonstrating that the transformer's learned attention weights prioritize the physiological signals that provide the earliest warning of stress. The z-score normalization within each parameter reveals that the model captures both the rate of decline and the absolute magnitude of physiological change, enabling it to distinguish between transient environmental fluctuations and the cumulative effects of soil water depletion.

\subsection{Validation of Pre-symptomatic Detection and Triangulation}\label{sec:results:triangulation}

The three-way triangulation protocol successfully quantified the physiology-visibility gap. For the stressed plants, we observed a consistent temporal sequence: the fluorescence change point (earliest metabolic deviation) typically occurred first, followed by the model's internal attention peak, and finally the expert-annotated visible onset. We calculated a Pearson correlation of $r=0.414$ between the fluorescence change point DAG and the model's attention peak DAG across all genotypes. This provides empirical evidence that the model's learned temporal importance is tracking real physiological shifts. On average, the model's internal detection of stress preceded human visible observation by several days, validating the framework's utility as a pre-symptomatic screening tool.

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/fig4_probability_curves.pdf}
  \caption{Temporal stress probability trajectories for representative plants. Each curve shows the model's predicted stress probability over time for individual plants, with vertical dashed lines indicating the expert-annotated stress onset DAG.}\label{fig:prob_curves}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/fig5_presymptomatic_timeline.pdf}
  \caption{Pre-symptomatic detection timeline showing the temporal relationship between fluorescence divergence, model detection, and human annotation. The framework consistently identifies stress signals before visible symptoms appear, validating the physiology-visibility gap bridging.}\label{fig:presymptomatic}
\end{figure}

\subsection{Analysis of Late-timepoint Errors and Senescence}\label{sec:results:errors}

Further analysis of the model's specificity revealed an increase in false positives during the late reproductive stages of the experiment (DAG 31--38). In the well-watered control group (WHC-80), the false positive rate increased to between 6\% and 20\% depending on the genotype. Visual examination confirmed that these errors were primarily due to natural senescence; aging faba bean plants exhibit leaf yellowing and structural changes that visually mimic late-stage drought stress. This highlights the fundamental challenge of decoupling drought-induced decline from normal developmental aging in long-term phenotyping experiments.


%% ============================================================
\section{Discussion}\label{sec:discussion}
%% ============================================================

\subsection{Effectiveness of Multimodal Fusion for Drought Phenotyping}\label{sec:discussion:fusion}

The results of this study provide compelling evidence that the integration of diverse sensor modalities---visual, physiological, and environmental---significantly enhances the sensitivity and robustness of drought phenotyping. The core advantage of our framework lies in its ability to navigate the complex trade-offs between different data types. While DINOv2 provides a dense, 768-dimensional representation of the plant's visual state, its diagnostic utility is inherently delayed by the physiology-visibility gap. Morphological changes such as wilting or leaf rolling are terminal symptoms of water deficit, appearing only after the plant's internal hydraulic systems have reached a tipping point. Conversely, chlorophyll fluorescence, though represented by a lower-dimensional set of parameters (94 in our study), provides a direct and immediate probe into the metabolic state of the photosynthetic apparatus.

The adaptive gating mechanism proved to be a decisive factor in achieving this synergy. By dynamically weighting the modalities at each timepoint, the model successfully implemented a temporal hierarchy of sensors. During the pre-symptomatic phase, the model's reliance on fluorescence was at its peak ($0.078$), allowing it to detect the metabolic shifts associated with reduced stomatal conductance and impaired electron transport. As the stress intensified and manifested as obvious structural changes, the gating mechanism shifted the focus to the visual features ($0.963$), which provided a more robust and persistent signal of severe decline. This dynamic prioritization is essential for developing models that remain accurate throughout the entire duration of a drought event, from the first sign of physiological strain to the onset of permanent wilting. Our findings suggest that multimodal fusion is not merely about adding more data, but about creating an architecture that understands when each sensor is most relevant---a principle that is likely applicable to a wide range of biotic and abiotic plant stresses.

\subsection{Theoretical Context: Fluorescence as Privileged Information (LUPI)}\label{sec:discussion:lupi}

A central theoretical contribution of this work is the application of the Learning Using Privileged Information (LUPI) paradigm to plant phenotyping. LUPI, originally proposed by Vapnik, posits that a model can be trained with access to high-quality but expensive data (privileged information) that is only available during the training phase, not during deployment \citep{vapnik2009learning, lopez2016unifying}. In our framework, chlorophyll fluorescence acts as this privileged signal. While ChlF measurements are too slow and labor-intensive for widespread field deployment or every-round monitoring in large-scale breeding, they are invaluable for defining the ground-truth physiological state during the development of deep learning models.

By training the temporal transformer in an environment where fluorescence is available, the model learns to associate subtle, often imperceptible visual patterns in the RGB data with the underlying photosynthetic decline. This ``physiological grounding'' of the visual representation allows the model to become sensitive to pre-symptomatic cues that a model trained solely on RGB labels might ignore as noise. Our results, particularly the 0.651 F1-score of the fluorescence-only variant, underscore the high information content of this modality. The successful triangulation between fluorescence change points and model attention peaks confirms that the transformer has indeed learned to attend to the same physiological tipping points that are captured by precision instrumentation. This paradigm offers a clear path toward the next generation of phenotyping tools: using high-end labs and precision sensors to train robust, scalable models that can eventually be deployed on standard cameras, UAVs, or even smartphone-based systems in the field.

\subsection{The Value of Temporal Dynamics and Sequence Modeling}\label{sec:discussion:temporal}

The 5.0\% performance drop observed when the temporal transformer was removed (the ``No Temporal'' ablation) highlights the fundamental importance of modeling drought as a progressive process rather than a static state. In faba bean, the response to water deficit is highly dynamic and genotype-dependent. Some genotypes follow a ``water-saving'' strategy, closing stomata early and exhibiting a rapid but controlled decline in photosynthetic efficiency, while others follow a ``water-spending'' strategy, maintaining growth until a sudden hydraulic failure occurs. By processing the entire 22-round measurement sequence, the transformer can capture these varied trajectories and distinguish between transient environmental fluctuations (e.g., a particularly hot afternoon) and the cumulative, persistent effects of soil water depletion.

The use of continuous sinusoidal positional encodings was critical for this longitudinal modeling. Unlike standard NLP tasks where tokens are equidistant, phenotyping experiments are often subject to irregular imaging intervals due to logistical constraints or sensor availability. Our encoding method allowed the model to correctly interpret the actual days after germination (DAG), providing it with a sense of the plant's developmental age and the rate of stress progression. This temporal awareness is what enables the model to identify the ``onset'' point with such accuracy. Furthermore, the bidirectional nature of the transformer allowed the model to refine its understanding of the ambiguous pre-symptomatic phase by looking backward from the more obvious symptomatic stages. This retrospectively informed detection is particularly useful for breeding applications where the final tolerance ranking is the primary goal, allowing for a more accurate reconstruction of each genotype's resilience profile.

\subsection{Mechanistic Insights from Feature Analysis: Bridging Visual and Physiological Representations}\label{sec:discussion:features}

The feature analysis presented in the Results section provides critical mechanistic insights into how the framework bridges the physiology-visibility gap. The DINOv2 embedding space analysis demonstrated that a frozen, general-purpose vision foundation model captures treatment-level visual differences despite not being explicitly trained on drought phenotypes. The partial clustering observed in both t-SNE and UMAP projections (2,905 embeddings from 264 plants) reflects the genotype-dependent nature of visual stress responses, consistent with the model's learned reliance on visual features for late-stage detection. More importantly, the strong correlations between DINOv2 embeddings and chlorophyll fluorescence parameters (80 of 94 parameters with |r| > 0.3, top three at r $\approx$ 0.85) validate the privileged information paradigm: by training with access to high-resolution fluorescence data, the model learns to associate subtle visual cues with the underlying photosynthetic machinery's state. The temporal dynamics analysis further confirms this mechanistic grounding. The data-driven parameters selected by the model (Fv\_Lss, Fq\_Lss, Fv/Fm\_Lss) exhibited earlier and more pronounced divergence between treatments (DAG 12--15) compared to classic PAM indices (DAG 17--20), aligning precisely with the model's mean onset error of $-1.2$ days. This temporal advantage demonstrates that the transformer's learned attention weights prioritize physiological signals that provide the earliest warning of stress, effectively learning to extract the most informative temporal features from the multimodal data stream. Together, these findings establish that the framework's pre-symptomatic detection capability is not merely a statistical artifact but is grounded in the physiological reality of drought stress progression, where metabolic changes in the photosynthetic apparatus precede visible morphological symptoms.

\subsection{Analysis of Late-timepoint False Positives and the Senescence Confound}\label{sec:discussion:fp}

Despite the overall success, the 6--20\% false positive rate observed in well-watered control plants at the end of the experiment (DAG 31--38) identifies a significant challenge for the field of automated phenotyping. This spike in errors is a direct consequence of the physiological and morphological overlap between drought stress and natural senescence. As faba bean plants age, especially as they transition from vegetative to reproductive stages, the lower leaves naturally undergo programmed cell death. This process involves the degradation of chlorophyll, the remobilization of nitrogen, and a decrease in $F_v/F_m$---shifts that are biochemically and visually remarkably similar to those induced by drought.

Our analysis confirms that the visual and physiological features utilized in this study are not yet specific enough to perfectly decouple these two processes. The model, sensitive to leaf yellowing and declining photosynthetic efficiency, correctly identifies these as signals of decline but incorrectly attributes them to water stress in the control group. This confound is especially problematic for long-term monitoring systems designed to operate throughout the entire life cycle of the crop. Future iterations of this framework should focus on ``un-mixing'' these signals. Potential strategies include the integration of hyperspectral data to identify unique spectral signatures of senescence-specific pigments or the use of multi-task learning where the model is explicitly trained to predict the developmental stage (phenological stage) alongside the stress state. Addressing the senescence confound is essential for ensuring the specificity of early-warning systems, particularly in late-season applications when distinguishing between drought and natural maturity is critical for timing harvest and managing irrigation.

\subsection{Generalization to Other Species and Environmental Scenarios}\label{sec:discussion:generalization}

While this study focused specifically on faba bean, the architecture and underlying philosophy of the temporal multimodal framework are designed for broad applicability across the plant sciences. Leguminous crops, including pea (\textit{Pisum sativum}), lentil (\textit{Lens culinaris}), and soybean (\textit{Glycine max}), share similar physiological drought response mechanisms, such as ABA-mediated stomatal control and the eventual decline in PSII efficiency. Our use of a frozen vision foundation model (DINOv2) is a key factor in this potential for generalization. Because DINOv2 was trained on a massive diversity of natural images, its feature space is not over-specialized to faba bean morphology, suggesting that the same visual representations could be utilized for other crops with minimal adaptation.

Furthermore, the adaptive gating mechanism allows the framework to handle the species-specific timing of stress symptoms. For instance, in crops that exhibit more rapid wilting than faba bean, the model would likely learn to transition from physiological to visual features even earlier in the stress cycle. The temporal transformer, with its continuous positional encodings, is also well-suited for different imaging schedules, making it a flexible tool for both high-frequency greenhouse monitoring and lower-frequency field campaigns. Future research should investigate the transferability of the learned temporal priors---specifically the relationship between ChlF decline and visual changes---to other economically important species. Validating the framework under varying soil types and multi-stress scenarios (e.g., combined drought and heat) will be essential for developing truly universal early-warning systems for global agriculture.

\subsection{Implications for Breeding and Precision Agriculture}\label{sec:discussion:implications}

The practical utility of our temporal multimodal framework is two-fold, offering significant benefits to both plant breeders and agronomists. For breeding programs, the ability to accurately rank 44 genotypes based on their physiological stress response represents a major advancement over traditional endpoint measurements such as final biomass or yield. Our LOGO-CV validation results prove that the model's ranking is robust to genotypes it has never seen before, making it a reliable tool for selecting the most resilient accessions from large germplasm panels. The pre-symptomatic detection capability allows breeders to identify ``early responders''---genotypes that prioritize physiological safety---and differentiate them from ``late responders'' that may maintain appearance at the cost of severe internal damage. This high-throughput physiological profiling can significantly accelerate the development of drought-resilient varieties tailored for specific environmental niches.

For precision agriculture, the early-warning signal detected by our model provides a vital lead-time for management intervention. In large-scale greenhouse or field operations, automated irrigation systems could be triggered by the framework's pre-symptomatic stress probability rather than waiting for visible wilting. This ``just-in-time'' irrigation strategy could stabilize yields while drastically reducing water consumption, a critical requirement for sustainable farming in water-scarce regions. Moreover, the framework's reliance on common sensors like RGB cameras (guided by the privileged knowledge of fluorescence) makes it economically viable for deployment. By bridging the gap between high-precision laboratory research and high-throughput industrial applications, this work provides a scalable computational foundation for the future of smart, resilient agriculture.


%% ============================================================
\section{Conclusion}\label{sec:conclusion}
%% ============================================================

This study has successfully developed and validated a temporal multimodal deep learning framework for the pre-symptomatic detection of drought stress in faba bean (\textit{Vicia faba} L.). By synthesizing high-dimensional features from the DINOv2 vision foundation model with precision chlorophyll fluorescence, environmental data, and vegetation indices, we achieved a robust F1-score of $0.634$ and an AUC of $0.949$ across a genetically diverse panel of 44 genotypes. Our adaptive gating mechanism and temporal transformer encoder proved essential for capturing the longitudinal dynamics of stress and navigating the physiology-visibility gap. Crucially, we provided empirical validation through a three-way triangulation protocol that the framework identifies physiological stress signals significantly before they manifest as visible morphological symptoms. This work demonstrates the power of combining modern AI representations with traditional physiological knowledge, offering a scalable and robust tool for accelerating the breeding of drought-resilient crops and optimizing irrigation management in the face of a changing climate.


%% ============================================================
\section{Data and Code Availability}\label{sec:data}
%% ============================================================

The source code for the temporal multimodal framework, including the adaptive gating module, the temporal transformer implementation, and the evaluation pipelines, is available at \url{https://github.com/chenghao/faba-drought-phenotyping}. The aggregated results summary, pre-symptomatic analysis datasets, and genotype-level metadata are provided in the repository's data folder. Raw imaging data (approximately 11,600 images) and full chlorophyll fluorescence measurement files are available from the corresponding author upon reasonable request.


\section*{Acknowledgements}

This work was supported by the Academy of Finland (Project No. XXXXXXX) and the Strategic Research Council. We thank the staff at the Luke Viikki greenhouse facility for their assistance with plant maintenance and the automated phenotyping platform.

%% CRediT authorship contribution statement
\printcredits

%% Bibliography
\bibliographystyle{cas-model2-names}
\bibliography{references}

\end{document}
